{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/todmiv/parser_vet/blob/bot_telegram/telegram_bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNK6g_J5Fmae"
      },
      "outputs": [],
      "source": [
        "# Инсталяция библиотек\n",
        "!pip install faiss-cpu langchain openai==0.28 tiktoken python-docx telebot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "N6A5fmFjH9D7"
      },
      "outputs": [],
      "source": [
        "# Импортируем необходимые библиотеки\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.document_loaders import TextLoader\n",
        "import os\n",
        "import getpass\n",
        "import re\n",
        "import requests\n",
        "import docx\n",
        "import openai\n",
        "from langchain.docstore.document import Document\n",
        "import logging\n",
        "from textwrap import fill\n",
        "logging.getLogger(\"langchain.text_splitter\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"chromadb\").setLevel(logging.ERROR)\n",
        "import telebot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebsLrthmH9Gx",
        "outputId": "1976b658-593c-45da-c583-2cecbb744cd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI API Key:··········\n"
          ]
        }
      ],
      "source": [
        "# Получение ключа API от пользователя и установка его как переменной окружения\n",
        "openai_key = getpass.getpass(\"OpenAI API Key:\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_key\n",
        "openai.api_key = openai_key\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UwId_uFMH9L9"
      },
      "outputs": [],
      "source": [
        "# функция для загрузки документа по ссылке из гугл драйв\n",
        "def load_document_text(file_name: str) -> str:\n",
        "    doc = docx.Document(file_name)\n",
        "    text = '\\n'.join([paragraph.text for paragraph in doc.paragraphs])\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "STYgV8MvH9Ja"
      },
      "outputs": [],
      "source": [
        "# Инструкция для GPT, которая будет подаваться в system\n",
        "system = '''Ты опытный Ветеринарный врач, проводящий консультации в ветеринарной клинике «ДАР».\n",
        "Твоя задача - помогать пользователям на основе подробного Руководства.\n",
        "Пользователь обращается к Тебе с вопросом. Твоя цель - подробно объяснить ,\n",
        "как решить его вопрос полагаясь исключительно на информацию из Руководства.\n",
        "1. Если вопрос пользователя неоднозначен, предложите несколько вариантов уточняющих вопросов.\n",
        "иначе\n",
        "1. Дай пользователю подробные инструкции для всех шагов, которые необходимы для решения его вопроса.\n",
        "2. Отвечай максимально точно и не добавляй ничего от себя.\n",
        "3. Последовательность шагов для разных действий может быть уникальна, пожалуйста, не предполагай,\n",
        "что она применима к тем действиям, для которых нет описания в Руководстве.\n",
        "4. Если в Руководстве нет точного ответа, пожалуйста, ответь, что Тебе требуестся дополнительная информация для полноценного ответа.\n",
        "5. Если в Руководстве есть информация для ответа, включи ее в ответ.\n",
        "6. Если Ты можешь предложить альтернативное решение задачи пользователя - обязательно сделай это.\n",
        "7. В ответе категорически нельзя упоминать предоставленные тебе Руководства и Отрывки из Руководства.\n",
        "9. К каждому отрывку Руководства задай по одному вопросу близкому по смыслу к вопросу Пользователя. В Твоих вопросах должно обязательно содержаться то же действие, что и в вопросе пользователя.\n",
        "10. Если в ответе ты хочешь сослаться на Руководство или Отрывок из Руководства переформулируй ответ без таких ссылок.\n",
        "\n",
        "Ответ дай в формате:\n",
        "Ветврач: текст ответа.\n",
        "Близкие вопросы:\n",
        "1. Вопрос1\n",
        "2. Вопрос2\n",
        "3. Вопрос3\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Htz95GxNLmnY"
      },
      "outputs": [],
      "source": [
        "# База знаний, которая будет подаваться в langChain\n",
        "database= load_document_text('df.docx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "iUaCRZzzYL71"
      },
      "outputs": [],
      "source": [
        "# Делим текст на чанки и создаем индексную базу\n",
        "source_chunks = []\n",
        "splitter = CharacterTextSplitter(separator=\"\\n\", chunk_size=500, chunk_overlap=0)\n",
        "\n",
        "for chunk in splitter.split_text(database):\n",
        "    source_chunks.append(Document(page_content=chunk, metadata={}))\n",
        "\n",
        "# Инициализирум модель эмбеддингов\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "# Создадим индексную базу из разделенных фрагментов текста\n",
        "db = FAISS.from_documents(source_chunks, embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "xGnU7uRoYL-j"
      },
      "outputs": [],
      "source": [
        "# Выбор модели, значение температуры и функции\n",
        "#MODEL_TURBO_16K = \"gpt-3.5-turbo-16k\"\n",
        "MODEL_TURBO_0613 = \"gpt-3.5-turbo-0613\"\n",
        "temperature= 0\n",
        "\n",
        "def create_completion(model, system, content, temperature):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system},\n",
        "        {\"role\": \"user\", \"content\": content}\n",
        "    ]\n",
        "\n",
        "    completion = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature\n",
        "\n",
        "    )\n",
        "    return completion.choices[0].message.content\n",
        "\n",
        "def answer_index(system, topic, search_index, temperature=0, verbose=0):\n",
        "    docs = search_index.similarity_search(topic, k=4)\n",
        "    message_content = ' '.join([f'\\nОтрывок документа №{i+1}\\n=====================' + doc.page_content + '\\n' for i, doc in enumerate(docs)])\n",
        "    question_content = f\"Документ с информацией для ответа клиенту: {message_content}\\n\\nВопрос клиента: \\n{topic}\"\n",
        "    return fill(create_completion(MODEL_TURBO_0613, system, question_content, temperature))\n",
        "\n",
        "def summarize_questions(dialog):\n",
        "    content = \"Суммаризируй следующий диалог ассистента отдела обслуживания клиентов и клиента: \" + \" \".join(dialog)\n",
        "    return create_completion(MODEL_TURBO_0613, \"Ты - ассистент, который умеет профессионально суммаризировать присланные тебе диалоги. Твоя задача - суммаризировать диалог, который тебе пришел. Отражай имя клиента в саммаризации\", content, 0)\n",
        "\n",
        "def answer_user_question_dialog(system: str, db: str, user_question: str, question_history: list) -> str:\n",
        "    summarized_history = \"\"\n",
        "    if question_history:\n",
        "        summarized_history = \"Вот краткий обзор предыдущего диалога: \" + summarize_questions([f'{q} {a or \"\"}' for q, a in question_history])\n",
        "    input_text = f\"{summarized_history}\\n\\nТекущий вопрос: {user_question}\"\n",
        "    answer_text = answer_index(system, input_text, db)\n",
        "    question_history.append((user_question, answer_text or ''))\n",
        "    return fill(answer_text)\n",
        "\n",
        "def run_dialog(user_question, system=system, db=db):\n",
        "    question_history = []\n",
        "    dialog = \"\"\n",
        "    answer = answer_user_question_dialog(system, db, user_question, question_history)\n",
        "    dialog += f'\\nЯ: {user_question} \\n Ветврач: {answer}'\n",
        "    #print('\\nВетврач: ', answer, '\\n')\n",
        "    return answer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1x137AGfnehc"
      },
      "outputs": [],
      "source": [
        "# Токен для телеграм\n",
        "TOKEN = '6691485723:AAFHHB3OEYcFEvsLvs7icK4-ia6WYGWKX5g'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "U0125PhlniSE"
      },
      "outputs": [],
      "source": [
        "# Инициализация бота\n",
        "bot = telebot.TeleBot(TOKEN)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для команды /start\n",
        "@bot.message_handler(commands=['start'])\n",
        "def start(message):\n",
        "    bot.reply_to(message, \"Привет! Я бот. Чем могу помочь?\")"
      ],
      "metadata": {
        "id": "XrrMpPP3NhOI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для команды /help\n",
        "@bot.message_handler(commands=['help'])\n",
        "def help_command(message):\n",
        "    bot.reply_to(message, \"Это пример телеграм бота. Он может преобразовывать введенный текст в заглавные буквы.\")"
      ],
      "metadata": {
        "id": "TXLhuX-RNjHT"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "AnTYIVPkno69"
      },
      "outputs": [],
      "source": [
        "# Функция вопрос/ответ\n",
        "@bot.message_handler(content_types=['text'])\n",
        "def dialog_text(message):\n",
        "    text = run_dialog(message.text)\n",
        "    bot.reply_to(message, text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjMbRRmKnjA1"
      },
      "outputs": [],
      "source": [
        "# Старт бота\n",
        "bot.polling()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}